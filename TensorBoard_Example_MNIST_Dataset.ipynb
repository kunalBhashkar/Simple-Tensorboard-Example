{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/kunal/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#importing the packages\n",
    "from keras.models import Sequential\n",
    "from keras import initializers\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define parameters \n",
    "batch_size = 128\n",
    "nb_epoch = 20"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: In neural networks, an epoch is equivalent to training the network using each data once. The number of epochs, nb_epoch, is hence how many times you re-use your data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for MNIST dataset\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters for MLP\n",
    "prob_drop_input = 0.2              \n",
    "prob_drop_hidden = 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape, name=None):\n",
    "    return initializers.normal(shape, scale=0.01, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MNIST dataset\n",
    "MNIST (Mixed National Institute of Standards and Technology) database is dataset for handwritten digits, distributed by Yann Lecun’s THE MNIST DATABASE of handwritten digits website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "Y_Train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_Test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron\n",
    "A Multi Layer Perceptron (MLP) contains one or more hidden layers (apart from one input and one output layer).  While a single layer perceptron can only learn linear functions, a multi layer perceptron can also learn non – linear functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense1 (Dense)               (None, 625)               490625    \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 625)               391250    \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 10)                6260      \n",
      "=================================================================\n",
      "Total params: 888,135\n",
      "Trainable params: 888,135\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=784, activation=\"sigmoid\", name=\"dense1\", units=625, kernel_initializer=\"normal\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/kunal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=625, activation=\"sigmoid\", name=\"dense2\", units=625, kernel_initializer=\"normal\")`\n",
      "  \"\"\"\n",
      "/home/kunal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=625, activation=\"softmax\", name=\"dense3\", units=10, kernel_initializer=\"normal\")`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Multilayer Perceptron model\n",
    "model = Sequential()\n",
    "model.add(Dense(output_dim=625, input_dim=784, init=\"normal\", activation='sigmoid', name='dense1'))\n",
    "model.add(Dropout(prob_drop_input, name='dropout1'))\n",
    "model.add(Dense(output_dim=625, input_dim=625, init=\"normal\", activation='sigmoid', name='dense2'))\n",
    "model.add(Dropout(prob_drop_hidden, name='dropout2'))\n",
    "model.add(Dense(output_dim=10, input_dim=625, init=\"normal\", activation='softmax', name='dense3'))\n",
    "model.compile(optimizer=RMSprop(lr=0.001, rho=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  256/60000 [..............................] - ETA: 35s - loss: 0.3776 - acc: 0.8984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/lib/python3.6/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.2522 - acc: 0.9226\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 30s 493us/step - loss: 0.1818 - acc: 0.9444\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 26s 434us/step - loss: 0.1443 - acc: 0.9557\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 25s 416us/step - loss: 0.1180 - acc: 0.9637\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.1034 - acc: 0.9682\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 28s 463us/step - loss: 0.0894 - acc: 0.9728\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.0796 - acc: 0.9756\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 26s 428us/step - loss: 0.0704 - acc: 0.9781\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.0638 - acc: 0.9798\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 24s 406us/step - loss: 0.0602 - acc: 0.9810\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 28s 469us/step - loss: 0.0551 - acc: 0.9827\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 29s 486us/step - loss: 0.0520 - acc: 0.9838\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 29s 490us/step - loss: 0.0468 - acc: 0.9855\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 29s 487us/step - loss: 0.0438 - acc: 0.9866\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 29s 489us/step - loss: 0.0414 - acc: 0.9869\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 29s 486us/step - loss: 0.0388 - acc: 0.9879\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 29s 489us/step - loss: 0.0362 - acc: 0.9887\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 29s 490us/step - loss: 0.0345 - acc: 0.9892\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 29s 489us/step - loss: 0.0319 - acc: 0.9899\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 29s 489us/step - loss: 0.0309 - acc: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe728c600b8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(X_train, Y_Train, nb_epoch=nb_epoch, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb =TensorBoard(log_dir='Graph', histogram_freq=0,write_graph=True, write_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb.set_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 230us/step\n",
      "\n",
      "Summary: Loss over the test dataset: 0.08, Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluation = model.evaluate(X_test, Y_Test, verbose=1)\n",
    "print('Test DataSet Loss: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kunal/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/kunal/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "TensorBoard 0.4.0 at http://kunal-Inspiron-N5010:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard  --logdir Graph/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
